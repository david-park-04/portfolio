A perceptron is a linear classifier that makes predictions based on a weighted sum of input features.

# Idea
A perceptron is composed of:
- **Feature Vector
	- Inputs are feature values
	- Each feature has a weight
	- Sum is the activation, whose sign determines the binary output
- **Weights Vector**
	- The feature vector is compared with the weights vector
	- The weights vector is adjusted accordingly from examples

# Decision Rules
Decision rules are how we determine the class of some input.

## Binary Decision Rules
The input is classified into one of two categories.

### Weight Updates
- Start with the weights = 0, unless a better guess is available
- Classify with the current weights
	- If classification is correct, the weights stay the same
	- If classification is incorrect, adjust the weights vector according to:

		$w = w + y^{*} \cdot f$
		
## Multi-class Decision Rules
The input is classified into one of multiple classes.

Each class has a weights vector. The class that we predict is the class whose activation is the highest. This is represented through:

$y = arg_{y}max w_{y} \cdot f(x)$

### Weight Updates
- Start with all weights = 0
- Classify with the current weights, making selections based on the class with the highest activation
	- If the classification is correct, the weights stay the same
	- If the classification is incorrect, we lower the score of the wrong answer and raise the score of the right answer:

		$w_{y} = w_{y} - f(x)$
		$w_{y}^{*} = w_{y}^{*} + f(x)$   

- Given separability, meaning it's possible to find a perfectly correct solution to our data set, the perceptron will eventually converge with mistakes bounded the the mistake bound

## Alternative Weight Updating Technique
MIRA (Margin Infused Relaxed Algorithm): Minimizes the changes to the weights as to just correct mistakes