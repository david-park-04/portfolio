A Bayes Net is a graphical model, a directed acyclic graph, that represents the Joint Probability Distribution for some random variables and thus enables easy inference.

# Structure
- The conditional probability table is written for every variable given its ancestors
- Each node is a random variable
- Each edge asserts a dependency

# Idea
Instead of having to write a massive probability table, we factorize the Joint Probability Distribution:

$P(X_1, X_2, X_n) = \prod_{i=1}^{n} P(X_i | Parents(X_i))$

# Determining (In)Dependence Between Nodes
- A node's Markov blanket is the smallest set of nodes to determine that a node is independent of its network. The blanket if formed by the node's parent, children, and children's parents.

## Local Semantics (Parent define dependence)
A node is conditionally independent of its non-descendants given its parents.

## Global Semantics (Full network)
### D-Separation
A graph-based method for determining independence. Strict d-separation:

1) Chain Rule
	- Unobserved: Dependence
	- Observed: Independent
2) Converging Structure
	- Unobserved: Independent
	- Observed: Dependent
3) Diverging Structure
	- Unobserved: Dependent
	- Observed: Independent

### Computing Probabilities with Chain Rule
The formula for calculating probabilities with chain rule is as follows:

$P(A,B) = P(A|B) \cdot P(B)$

Or more simply, you can write the probabilities of every variable given its parents, just referencing the Bayes Net.

Once the formula for the desired probability is obtained, the conditional probability tables allow us to calculate.

In cases of marginal probabilities, we have to consider cases, summing over the variable's parent.